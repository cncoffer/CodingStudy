### 18 并发 ###

### 18.1 高级接口: async()和future ###

看了这一章, 才发现我对于并发的理解还局限在多线程上, 但并发并不仅仅是创建多线程, 比如可以使用async()来实现并发.

他的实现在<future>中.

用起来很简单, 创建一个future对象保存结果, 然后使用async运行函数.
	future<int> ret1(async(fun1));
	int ret2 = fun2();
	int result = ret1.get() + ret2;

对于支持并行的环境就会并发进行, 对于不支持或者线程不够的环境, 就会顺序执行.
也就是说能够让程序在并行环境收益, 在单线程环境也正确运行.

但要注意的是, 上面的正确性只在不存在数据竞争的情况下保证.

另外, ret1.get()是需要等待async运行结束的, 也就是说这一调用应该在不得不用到的地方调用, 否则并行的收益就会下降. 也就是早调用而晚返回, 能够保证收益最大化.

async可以接受任何类型的callable object, 也就是说能够将lambda放在线程中运行, 听起来很不错不是吗.

然后, 对于async可以指定std::launch::async, std::launch::deferred, 分别表示强制立即执行和强制延迟执行.
于是使用deferred可以写出下面这样的代码:
	auto f1 = std::async(std::launch::deferred, task1);
	auto f2 = std::async(std::launch::deferred, task2);
	// do something
	auto val = thisOrTharIsTheCase() ? f1.get() : f2.get();

虽然和在用到的时候执行task1和task2性能上好像没什么区别...
不过在优化代码结构上会非常有用.

在异常上, async和正常的调用没有区别, 就像以前那样捕获异常即可.

- 等待
使用wait()可以强制启动future的线程并等待这一后台操作终止, 要获取他的结果还是用get().
使用wait_for(一个时间段), wait_until(time_point), 都可以等待一段时间, 然后返回future的状态, 会有三种状态
1. std::future_status::deferred		表示延缓操作, 而又没有调用wait()或get()来启动.
2. std::future_status::timeout		表示操作启动但是尚未结束, 并且waiting逾期.
3. std::future_status::ready		表示操作已完成.

使用wait_for和wait_until可以写出所谓的投机性运行. 进行一个复杂的计算和一个简单的计算, 如果到时间点了复杂的计算有结果就返回复杂的计算结果, 否则就返回简单的计算结果.
这种做法听起来非常酷, 有机会可以用用. 比如获取帧.


### 18.1.3 shared future ###

future只能get()一次, 而shared_future可以get()多次, 如果抛出异常也是在get()时抛出同样的异常多次.

### 18.2 低层接口: thread和promise ###

声明一个std::thread对象, 将目标任务当做初识实参, 然后要么等待他结束.join(), 要么将它卸离.detach().

高层接口async包装的更好一些, 接口和功能也丰富一些, 但是不保证是并行的.
低层接口thread是强制并行执行的, 但是接口和功能会少一些, 如果无法并行会抛出异常.

要当心detached thread.
因为这些线程如果使用的非local资源, 比如by reference传入的参数, 比如global和static object, 当程序结束时, detached thread可能还在运行, 那他就有可能访问已被销毁或正在析构的object.

threadID是唯一的, 只能用来比较和输出到stream, 然后他有可能在被申请的时候才动态分配, 所以id为多少并不意味着什么.

### 18.2.3 class packaged_task<> ###

可以把目标函数及其可能结果放在packaged_task<>中, 然后在需要的时候调用他.
有点绕, 但书中也没有给非常详细的例子, 用到的时候再查吧.

### 18.4 线程同步化与Concurrency问题 ###

并发访问会存在很多问题, 本小节先了解问题所在, 然后后面的章节再介绍解决办法.
C++11保证每个变量都拥有自己的内存区, 也就是说并发处理不同的的变量或对象或成员, 不会有问题.

什么情况下可能出错
1. 未同步化的数据访问, 即并发写同一数据.
2. 写至半途的数据, 即某线程正在读, 另一线程正在写.
3. 重新安排的语句, 语句和操作有可能被编译器重新安排次序(优化或者延迟执行), 导致和预期的行为不符.

例如下面例子
	thread1() {data = 42; readyFlag = true;}
	thread2() {
		while (!readyFlag) {} wait until data is ready
		foo(data);
	}

thread1()的第一行和第二行是有可能改变顺序的, 这就导致了thread2()的行为可能无法预期了.

### 18.4.4 解决问题所需要的性质 ###

1. atomicity, 不可切割性, 也就是所谓的原子操作.
2. order, 次序.

有下面这些方法可以处理
1. future和promise, 可以保证上面两点.
2. mutex和lock, 能保证atomicity.
3. condition varible, 有效的令多线程间的次序可控.
4. atomic data type, 确保每次对变量或对象的访问动作都是不可切割的.
5. atomic data type的底层接口, 有点复杂, 看到了再说.

这些方法从上到下, 是从高级排列至低层, 高级特性封装好易使用风险小, 低层特性也许性能好, 可伸缩性好, 但误用的风险更大.
atomic可以让我们做到lock-free编程, 但很能保证不出错.

### 18.5 mutex和lock ###

使用方法是声明一个mutex, 在数据访问的时候lock上, 用完了就unlock.
	int val;
	std::mutex valMutex;

	valMutex.lock();
	val++;
	valMutex.unlock();

但是上面这样写会有风险, 比如val++时异常退出了, mutex就永远锁上了.
为了保证不论怎样都能够释放资源, 应该使用RAII守则, 也就是在构造函数中获取资源, 在析构函数中自动释放资源.
C++标准库提供了class std::lock_guard:
	int val;
	std::mutex valMutex;

	{
		std::lock_guard<std::mutex> lg(valMutex);
		val++;
	}

递归lock, class recursive_mutex允许同一线程多次锁定, 并在last(我觉得应该是最后)响应的unlock()时释放lock.

尝试性lock, 使用try_lock()函数, 它会试图取得一个lock, 成功就返回true, 失败就返回false. 这样就不会因为等待而造成阻塞.
为了仍能够使用lock_guard, 可以传一个额外实参adopt_lock给其构造函数.
	std::mutex m;
	while (m.try_lock() == false)
	{
		doSomeOtherThings();
	}
	std::lock_guard<std::mutex> lg(m, std::adopt_lock);

处理多个lock
全局函数std::lock(), 会锁住他收到的所有mutex, 而且阻塞知道所有mutex都被锁定或抛出异常.
这样能回避因为lock顺序带来的deadlock.

### 18.5.3 只调用一次 ###

使用class once_flag和call_once()组合, 可以做到只调用一次, 对于延迟初始化非常有用.
	class MyClass
	{
	public:
		MyClass() : m_nNum(0) {};
		~MyClass() {};
		int GetNum() {
			call_once(m_initFlag, &MyClass::init, this);
	
			return m_nNum;
		}
	
	private:
		mutable once_flag m_initFlag;
		int m_nNum;
	
		void init() {
			m_nNum = 10;
			cout << "init()" << endl;
		}
	};

### 18.6 条件变量 ###

条件变量class condition_variable需要和mutex共同使用.

需要注意的是即使被唤醒了也需要检查数据是否准备好, 因为存在假醒的情况.

### 18.7 atomic ###

class atomic可以将对变量的读写编程原子操作, 所以不会出现读到一半写的情况.
但是如果要保证其执行顺序, 仍需要其他手段.

